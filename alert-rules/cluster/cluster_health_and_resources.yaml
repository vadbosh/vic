groups:
- name: cluster-nodes-availability
  rules:
  # 1.2 Node is not in Ready state (overall and by type/role)
  - alert: NodeNotReady
    expr: kube_node_status_condition{condition="Ready", status="true"} == 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node {{ $labels.exported_node }} is not Ready"
      description: "Node {{ $labels.exported_node }} has been unavailable for more than 5 minutes."

  # The_number_of_wsd_servers_is_less_than_2_K8s
  - alert: ClusterNodeCountCritical
    expr: count(kube_node_status_condition{condition="Ready", status="true"}) < 2
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Cluster node count is critical"
      description: "Less than 2 nodes are Ready in the cluster. High risk of outage."

- name: cluster-resources
  rules:
  # 1.3 CPU: Max load (Single node overload)
  - alert: NodeHighCPULoad
    expr: |-
      round(
            (1 - avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])))
            * on(instance) group_left(board_asset_tag, product_name) node_dmi_info
            * 100
           ) > 70
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "High CPU on {{ $labels.instance }}/{{ $labels.board_asset_tag }}/{{ $labels.product_name }}"
      description: "CPU load on node {{ $labels.instance }}/{{ $labels.board_asset_tag }}/{{ $labels.product_name }} is above {{ $value }}%."

  # 1.4 Memory: Max usage (Risk of OOM Killer on node)
  - alert: NodeHighMemoryUsage
    expr: |-
      round (sum by(board_asset_tag, eks_cluster_nodegroup, k8s_node_role, instance)
        (
         (
          container_memory_working_set_bytes{id="/"}
          / on(kubernetes_io_hostname) group_left()
          label_replace(
          kube_node_status_allocatable{resource="memory"},
          "kubernetes_io_hostname", "$1", "exported_node", "(.+)"
         )
        )
        * on(kubernetes_io_hostname) group_left(board_asset_tag)
        label_replace(node_dmi_info, "kubernetes_io_hostname", "$1", "node", "(.+)")
       ) * 100) > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High Memory on {{ $labels.instance }} ({{ $labels.k8s_node_role }})"
      description: |-
        Memory usage is at {{ $value | humanize }}% on node {{ $labels.instance }}
        (nodegroup: {{ $labels.eks_cluster_nodegroup }}, role: {{ $labels.k8s_node_role }}, asset: {{ $labels.board_asset_tag }})

  - alert: KubernetesMemoryPressure
    expr: |-
      (kube_node_status_condition{condition="MemoryPressure",status="true"} == 1)
      * on(exported_node) group_left(board_asset_tag, product_name)
      label_replace(node_dmi_info, "exported_node", "$1", "node", "(.+)")
    annotations:
      description: |-
        Node {{ $labels.exported_node }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) has MemoryPressure condition
    labels:
      severity: critical
    for: 2m

  - alert: KubernetesDiskPressure
    expr: |-
      (kube_node_status_condition{condition="DiskPressure",status="true"} == 1)
      * on(exported_node) group_left(board_asset_tag, product_name)
      label_replace(node_dmi_info, "exported_node", "$1", "node", "(.+)")
    annotations:
      description: |-
        Node {{ $labels.exported_node }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) has DiskPressure condition
    labels:
      severity: critical
    for: 2m

  # 1.5 CoreDNS
  - alert: CoreDNSPanic
    expr: sum(increase(coredns_panics_total[1m])) > 0
    labels:
      severity: critical
    annotations:
      summary: "CoreDNS panic detected"
      description: "CoreDNS raised {{ $value }} panics in the last minute."

  - alert: HostUnusualNetworkThroughputIn
    annotations:
      description: |-
        Host {{ $labels.instance }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) network interfaces are probably receiving too much data (> 100 MB/s)
    expr: |-
      (sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100)
      * on(instance) group_left(board_asset_tag, product_name)
      node_dmi_info
    labels:
      severity: warning
    for: 5m

  - alert: HostUnusualNetworkThroughputOut
    annotations:
      description: |-
        Host {{ $labels.instance }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) network interfaces are probably sending too much data (> 100 MB/s)
    expr: |-
      (sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100)
      * on(instance) group_left(board_asset_tag, product_name)
      node_dmi_info
    labels:
      severity: warning
    for: 5m

  - alert: HostUnusualDiskReadRate
    annotations:
      description: |-
        Disk on {{ $labels.instance }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) is probably reading too much data (> 50 MB/s)
    expr: |-
      (sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50)
      * on(instance) group_left(board_asset_tag, product_name)
      node_dmi_info
    labels:
      severity: warning
    for: 5m

  - alert: HostUnusualDiskWriteRate
    annotations:
      description: |-
        Disk on {{ $labels.instance }} ({{ $labels.board_asset_tag }}, {{ $labels.product_name }}) is probably writing too much data (> 50 MB/s)
    expr: |-
      (sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50)
      * on(instance) group_left(board_asset_tag, product_name)
      node_dmi_info
    labels:
      severity: warning
    for: 2m

  - alert: KubernetesPVVolumeOutOfDiskSpace
    expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Kubernetes Volume out of disk space instance {{ $labels.instance }}/{{ $labels.persistentvolumeclaim }}"
      description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  VOL = {{ $labels.persistentvolumeclaim }}"

  - alert: KubernetesPVCError
    expr: kube_persistentvolumeclaim_status_phase{phase=~"Lost|Pending"} > 0
    labels:
      severity: critical
    for: 5m
    annotations:
      summary: "PVC {{ $labels.persistentvolumeclaim }} is bad"
      description: "PVC {{ $labels.persistentvolumeclaim }} in NS {{ $labels.exported_namespace }} is in {{ $labels.phase }} state."

  # -------------------------------------------------------------
  # 1. FILESYSTEM (Disk Space & Inodes)
  # -------------------------------------------------------------

  # Optimization: Filter directly by label fstype inside the metric.
  # Excludes 'tmpfs', 'overlay' (docker), and other noise.
  - alert: HostOutOfDiskSpace
    expr: |
      (
        node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} * 100
        /
        node_filesystem_size_bytes
      ) < 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} out of disk space"
      description: "Disk {{ $labels.mountpoint }} ({{ $labels.device }}) is almost full. Only {{ $value | printf \"%.2f\" }}% space left."

  - alert: HostOutOfInodes
    expr: |
      (
        node_filesystem_files_free{fstype!~"tmpfs|overlay"} * 100
        /
        node_filesystem_files
      ) < 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} out of inodes"
      description: "Disk {{ $labels.mountpoint }} is running out of inodes. Only {{ $value | printf \"%.2f\" }}% inodes left."

  # -------------------------------------------------------------
  # 2. CPU & IO
  # -------------------------------------------------------------

  - alert: HostCPUHighIowait
    expr: avg by (instance) (rate(node_cpu_seconds_total{mode="iowait"}[5m])) * 100 > 5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} high CPU iowait"
      description: "CPU iowait is {{ $value | printf \"%.2f\" }}%. Possible disk/network bottleneck."

  # -------------------------------------------------------------
  # 3. NETWORK
  # -------------------------------------------------------------

  # Filter: Exclude loopback (lo)
  - alert: HostNetworkReceiveErrors
    expr: |
      rate(node_network_receive_errs_total{device!="lo"}[2m])
      /
      rate(node_network_receive_packets_total{device!="lo"}[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} high network RX errors"
      description: "Interface {{ $labels.device }} has high receive error rate: {{ $value | printf \"%.2%\" }} of packets are failing."

  - alert: HostNetworkTransmitErrors
    expr: |
      rate(node_network_transmit_errs_total{device!="lo"}[2m])
      /
      rate(node_network_transmit_packets_total{device!="lo"}[2m]) > 0.01
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} high network TX errors"
      description: "Interface {{ $labels.device }} has high transmit error rate: {{ $value | printf \"%.2%\" }} of packets are failing."

  # -------------------------------------------------------------
  # 4. SYSTEM LIMITS
  # -------------------------------------------------------------

  - alert: HostConntrackLimit
    expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Host {{ $labels.instance }} conntrack limit approaching"
      description: "Conntrack table is {{ $value | printf \"%.2%\" }} full. Risk of dropping new connections."
